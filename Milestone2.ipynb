{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS5460 Milestone 2 - EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesting Files to PySpark\n",
    "\n",
    "Author: Anne Tumlin\n",
    "\n",
    "Date: 03/21/25\n",
    "\n",
    "Now that we have taken the files from the original GCS bucket, extracted them, and put them in our local GCS bucket (see `docs/EXTRACTION_PROCESS` in GitHub for more details), we can begin to ingest our data into PySpark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"app_name\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to edit the path with YOUR google storage bucket here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/*.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on a Small Scale\n",
    "Let's try this with only 100 files first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "client = storage.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: Change bucket_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"ds5460-tumlinam-fp-bucket\"\n",
    "bucket = client.get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List blobs (files) in the specified prefix and collect the first 100 file paths\n",
    "blobs = bucket.list_blobs(prefix=prefix)\n",
    "file_paths = []\n",
    "for blob in blobs:\n",
    "    file_paths.append(f\"gs://{bucket_name}/{blob.name}\")\n",
    "    if len(file_paths) >= 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the following 100 JSON file paths:\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15000.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15001.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15002.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15003.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15004.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15005.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15006.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15007.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15008.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15009.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15010.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15011.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15012.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15013.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15014.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15015.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15016.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15017.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15018.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15019.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15020.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15021.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15022.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15023.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15024.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15025.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15026.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15027.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15028.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15029.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15030.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15031.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15032.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15033.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15034.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15035.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15036.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15037.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15038.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15039.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15040.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15041.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15042.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15043.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15044.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15045.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15046.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15047.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15048.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15049.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15050.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15051.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15052.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15053.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15054.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15055.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15056.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15057.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15058.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15059.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15060.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15061.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15062.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15063.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15064.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15065.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15066.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15067.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15068.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15069.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15070.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15071.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15072.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15073.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15074.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15075.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15076.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15077.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15078.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15079.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15080.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15081.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15082.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15083.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15084.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15085.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15086.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15087.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15088.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15089.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15090.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15091.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15092.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15093.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15094.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15095.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15096.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15097.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15098.json\n",
      "gs://ds5460-tumlinam-fp-bucket/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15099.json\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading the following 100 JSON file paths:\")\n",
    "for path in file_paths:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE:** After testing and running into issues with the schema, I discovered that due to the way the JSON files are formatted we must utilize the multiline read option. Otherwise, our data will not be read in properly. Instead, it will lead to the error `|-- _corrupt_record: string (nullable = true)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to use multiline read option!\n",
    "df_small = spark.read.option(\"multiline\", \"true\").json(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- grid: struct (nullable = true)\n",
      " |    |-- context: array (nullable = true)\n",
      " |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |-- edges: struct (nullable = true)\n",
      " |    |    |-- ac_line: struct (nullable = true)\n",
      " |    |    |    |-- features: array (nullable = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |    |-- receivers: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- senders: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- generator_link: struct (nullable = true)\n",
      " |    |    |    |-- receivers: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- senders: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- load_link: struct (nullable = true)\n",
      " |    |    |    |-- receivers: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- senders: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- shunt_link: struct (nullable = true)\n",
      " |    |    |    |-- receivers: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- senders: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- transformer: struct (nullable = true)\n",
      " |    |    |    |-- features: array (nullable = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |    |-- receivers: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- senders: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |-- nodes: struct (nullable = true)\n",
      " |    |    |-- bus: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- generator: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- load: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- shunt: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: double (containsNull = true)\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- objective: double (nullable = true)\n",
      " |-- solution: struct (nullable = true)\n",
      " |    |-- edges: struct (nullable = true)\n",
      " |    |    |-- ac_line: struct (nullable = true)\n",
      " |    |    |    |-- features: array (nullable = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |    |-- receivers: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- senders: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- transformer: struct (nullable = true)\n",
      " |    |    |    |-- features: array (nullable = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |    |-- receivers: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- senders: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |-- nodes: struct (nullable = true)\n",
      " |    |    |-- bus: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- generator: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: double (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_small.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                grid|            metadata|            solution|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[[[[100.0]]], [[[...| [443934.8106702195]|[[[[[1.2271252469...|\n",
      "|[[[[100.0]]], [[[...|[465533.45792886155]|[[[[[1.3700529900...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_small.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on the Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"multiline\", \"true\").json(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Summarizing Relevant Datasets Code for the New Dataset\n",
    "  \n",
    "Author: Ewan Long\n",
    "  \n",
    "Date: 03/23/25\n",
    "  \n",
    "We are trying to test and revise the original code we have in the Milestone 1 as we changed our dataset (see `docs/EXTRACTION_PROCESS` in GitHub for reasons & more details), we have ingested our data into PySpark. \n",
    "  \n",
    "The following code will try to aggregate data and join the key tables (see Milestone 1 Notebook and doc for reasons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, initialize the SparkSession. We will process the first 100 JSON files here for faster processing and test verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "client = storage.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col, explode, input_file_name, expr, sum as spark_sum, avg, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/24 19:47:33 INFO SparkEnv: Registering MapOutputTracker\n",
      "25/03/24 19:47:33 INFO SparkEnv: Registering BlockManagerMaster\n",
      "25/03/24 19:47:33 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "25/03/24 19:47:33 INFO SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"app_name\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_path = \"gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/*.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change the bucket to your own's\n",
    "bucket_name = \"dataproc-temp-us-central1-299400297029-n5lhuci2\"\n",
    "bucket = client.get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = \"gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List blobs (files) in the specified prefix and collect the first 100 file paths\n",
    "blobs = bucket.list_blobs(prefix=prefix)\n",
    "file_paths = []\n",
    "for blob in blobs:\n",
    "    file_paths.append(f\"gs://{bucket_name}/{blob.name}\")\n",
    "    if len(file_paths) >= 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the following 100 JSON file paths:\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15000.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15001.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15002.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15003.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15004.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15005.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15006.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15007.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15008.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15009.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15010.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15011.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15012.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15013.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15014.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15015.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15016.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15017.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15018.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15019.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15020.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15021.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15022.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15023.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15024.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15025.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15026.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15027.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15028.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15029.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15030.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15031.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15032.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15033.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15034.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15035.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15036.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15037.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15038.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15039.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15040.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15041.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15042.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15043.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15044.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15045.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15046.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15047.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15048.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15049.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15050.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15051.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15052.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15053.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15054.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15055.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15056.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15057.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15058.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15059.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15060.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15061.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15062.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15063.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15064.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15065.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15066.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15067.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15068.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15069.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15070.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15071.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15072.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15073.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15074.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15075.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15076.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15077.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15078.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15079.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15080.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15081.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15082.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15083.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15084.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15085.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15086.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15087.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15088.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15089.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15090.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15091.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15092.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15093.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15094.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15095.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15096.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15097.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15098.json\n",
      "gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15099.json\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading the following 100 JSON file paths:\")\n",
    "for path in file_paths:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, read all JSON files with the multiline option enabled so that nested JSON is parsed correctly. Adding the original **filename** column for identification and join purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- grid: struct (nullable = true)\n",
      " |    |-- context: array (nullable = true)\n",
      " |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |-- edges: struct (nullable = true)\n",
      " |    |    |-- ac_line: struct (nullable = true)\n",
      " |    |    |    |-- features: array (nullable = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |    |-- receivers: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- senders: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- generator_link: struct (nullable = true)\n",
      " |    |    |    |-- receivers: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- senders: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- load_link: struct (nullable = true)\n",
      " |    |    |    |-- receivers: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- senders: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- shunt_link: struct (nullable = true)\n",
      " |    |    |    |-- receivers: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- senders: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- transformer: struct (nullable = true)\n",
      " |    |    |    |-- features: array (nullable = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |    |-- receivers: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- senders: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |-- nodes: struct (nullable = true)\n",
      " |    |    |-- bus: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- generator: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- load: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- shunt: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: double (containsNull = true)\n",
      " |-- metadata: struct (nullable = true)\n",
      " |    |-- objective: double (nullable = true)\n",
      " |-- solution: struct (nullable = true)\n",
      " |    |-- edges: struct (nullable = true)\n",
      " |    |    |-- ac_line: struct (nullable = true)\n",
      " |    |    |    |-- features: array (nullable = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |    |-- receivers: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- senders: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- transformer: struct (nullable = true)\n",
      " |    |    |    |-- features: array (nullable = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |    |-- receivers: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- senders: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |-- nodes: struct (nullable = true)\n",
      " |    |    |-- bus: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- generator: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: double (containsNull = true)\n",
      " |-- filename: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = spark.read.option(\"multiline\", \"true\").json(file_paths).withColumn(\"filename\", input_file_name())\n",
    "\n",
    "# Print the schema to verify that 'grid.nodes.generator' and others are parsed correctly.\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can do the data processing. Let's process generator data first. \n",
    "  \n",
    "I will explode nested JSON and extract generator attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------+--------------------+-----+--------+--------+-------+---+------------+-----------+-----------+\n",
      "|            filename|mbase|                 pg|                pmin| pmax|      qg|    qmin|   qmax| vg|cost_squared|cost_linear|cost_offset|\n",
      "+--------------------+-----+-------------------+--------------------+-----+--------+--------+-------+---+------------+-----------+-----------+\n",
      "|gs://dataproc-tem...| 46.9|            0.34463|             0.22026|0.469| 0.07856|-0.02298| 0.1801|1.0|         0.0|     3000.0|        0.0|\n",
      "|gs://dataproc-tem...|888.2|            6.43217|  3.9823399999999998|8.882| 1.27013|-0.72832|3.26858|1.0|       10.98|      910.9|        0.0|\n",
      "|gs://dataproc-tem...| 25.0|            0.16691| 0.08381999999999999| 0.25|0.041875|-0.01225|  0.096|1.0|         0.0|     3000.0|        0.0|\n",
      "|gs://dataproc-tem...| 25.0|            0.13858|0.027160000000000004| 0.25|0.041875|-0.01225|  0.096|1.0|         0.0|     3000.0|        0.0|\n",
      "|gs://dataproc-tem...| 25.0|0.17330500000000001|             0.09661| 0.25|0.041875|-0.01225|  0.096|1.0|         0.0|     3000.0|        0.0|\n",
      "+--------------------+-----+-------------------+--------------------+-----+--------+--------+-------+---+------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen_df = df.select(\n",
    "    \"filename\",\n",
    "    explode(\"grid.nodes.generator\").alias(\"generator_array\")\n",
    ").select(\n",
    "    \"filename\",\n",
    "    col(\"generator_array\")[0].alias(\"mbase\"),\n",
    "    col(\"generator_array\")[1].alias(\"pg\"),\n",
    "    col(\"generator_array\")[2].alias(\"pmin\"),\n",
    "    col(\"generator_array\")[3].alias(\"pmax\"),\n",
    "    col(\"generator_array\")[4].alias(\"qg\"),\n",
    "    col(\"generator_array\")[5].alias(\"qmin\"),\n",
    "    col(\"generator_array\")[6].alias(\"qmax\"),\n",
    "    col(\"generator_array\")[7].alias(\"vg\"),\n",
    "    col(\"generator_array\")[8].alias(\"cost_squared\"),\n",
    "    col(\"generator_array\")[9].alias(\"cost_linear\"),\n",
    "    col(\"generator_array\")[10].alias(\"cost_offset\")\n",
    ")\n",
    "\n",
    "gen_df.show(5) # verify the extracted attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try to aggregates generator features at the snapshort level, summarizing key characteristics for each filename.\n",
    "  \n",
    "The following statistics will be extracted and computed:\n",
    "- Total number of generators\n",
    "- Sum of generated power (pg)\n",
    "- Average generator voltage (vg)\n",
    "- Average generator cost parameters (quadratic, linear, and offset terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Aggregate generator features by snapshot (filename)\n",
    "gen_agg = gen_df.groupBy(\"filename\").agg(\n",
    "    count(\"*\").alias(\"num_generators\"),\n",
    "    spark_sum(\"pg\").alias(\"total_pg\"),\n",
    "    avg(\"vg\").alias(\"avg_vg\"),\n",
    "    avg(\"cost_squared\").alias(\"avg_cost_squared\"),\n",
    "    avg(\"cost_linear\").alias(\"avg_cost_linear\"),\n",
    "    avg(\"cost_offset\").alias(\"avg_cost_offset\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step would try to process and aggregate the power load data, extracting key load parameters (specifically real \"pd\" and reactive \"qd\" power demands) per snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+\n",
      "|            filename|                 pd|                  qd|\n",
      "+--------------------+-------------------+--------------------+\n",
      "|gs://dataproc-tem...|0.32349711373191603|  0.0541399530109636|\n",
      "|gs://dataproc-tem...| 0.8572351780984674|   0.253666451943297|\n",
      "|gs://dataproc-tem...| 0.5207840155565728| 0.12156684298552808|\n",
      "|gs://dataproc-tem...| 0.7133438352218501|0.039086170526506626|\n",
      "|gs://dataproc-tem...| 0.6837468540898303| 0.13888321084001698|\n",
      "+--------------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Extracting load data\n",
    "load_df = df.select(\n",
    "    \"filename\",\n",
    "    col(\"grid.nodes.load\").alias(\"load_arrays\")  \n",
    ").select(\n",
    "    \"filename\",\n",
    "    explode(\"load_arrays\").alias(\"load\")  \n",
    ").select(\n",
    "    \"filename\",\n",
    "    col(\"load\")[0].alias(\"pd\"),  \n",
    "    col(\"load\")[1].alias(\"qd\")\n",
    ")\n",
    "\n",
    "load_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Aggregate load features per snapshot\n",
    "load_agg = load_df.groupBy(\"filename\").agg(\n",
    "    count(\"*\").alias(\"num_loads\"),\n",
    "    spark_sum(\"pd\").alias(\"total_pd\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the next step would try to extract and aggregate transmission line features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+----------+---------+------------------+\n",
      "|            filename|      br_r|      br_x|    rate_a|   rate_b|            rate_c|\n",
      "+--------------------+----------+----------+----------+---------+------------------+\n",
      "|gs://dataproc-tem...|0.01340085|0.01340085| 0.0154525|0.0792528|            2.3994|\n",
      "|gs://dataproc-tem...| 0.0065814| 0.0065814|0.00358046|0.0258456|            2.6003|\n",
      "|gs://dataproc-tem...| 0.0065814| 0.0065814|0.00358046|0.0258456|            2.6003|\n",
      "|gs://dataproc-tem...| 0.0062579| 0.0062579|0.00319977|0.0219502|2.5658999999999996|\n",
      "|gs://dataproc-tem...|0.00557485|0.00557485|0.00696197|0.0360534|            2.1877|\n",
      "+--------------------+----------+----------+----------+---------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Extract transmission line features from grid.edges.ac_line.features\n",
    "ac_line_df = df.select(\n",
    "    \"filename\",\n",
    "    explode(\"grid.edges.ac_line.features\").alias(\"ac_line\")\n",
    ").select(\n",
    "    \"filename\",\n",
    "    col(\"ac_line\")[2].alias(\"br_r\"),\n",
    "    col(\"ac_line\")[3].alias(\"br_x\"),\n",
    "    col(\"ac_line\")[4].alias(\"rate_a\"),\n",
    "    col(\"ac_line\")[5].alias(\"rate_b\"),\n",
    "    col(\"ac_line\")[6].alias(\"rate_c\")\n",
    ")\n",
    "\n",
    "ac_line_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Aggregate transformer features per snapshot\n",
    "ac_line_agg = ac_line_df.groupBy(\"filename\").agg(\n",
    "    avg(\"br_r\").alias(\"br_r_mean\"),\n",
    "    avg(\"br_x\").alias(\"br_x_mean\"),\n",
    "    spark_sum(\"rate_a\").alias(\"rate_a_sum\"),\n",
    "    F.min(\"rate_b\").alias(\"rate_b_min\"),\n",
    "    F.max(\"rate_c\").alias(\"rate_c_max\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, extract and aggregate the Transformer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------+------+-------+\n",
      "|            filename|      br_r|     br_x|rate_a|    tap|\n",
      "+--------------------+----------+---------+------+-------+\n",
      "|gs://dataproc-tem...|5.36254E-4|0.0293108| 3.905| 1.0125|\n",
      "|gs://dataproc-tem...|5.05881E-4|0.0243569|5.0692|1.03125|\n",
      "|gs://dataproc-tem...|5.41271E-4|0.0336934|4.6108|    1.1|\n",
      "|gs://dataproc-tem...|5.41271E-4|0.0336934|4.6108|    1.1|\n",
      "|gs://dataproc-tem...|5.41271E-4|0.0336934|4.6108|    1.1|\n",
      "+--------------------+----------+---------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Extract transformer features from grid.edges.transformer.features\n",
    "trans_df = df.select(\n",
    "    \"filename\",\n",
    "    explode(\"grid.edges.transformer.features\").alias(\"trans\")\n",
    ").select(\n",
    "    \"filename\",\n",
    "    col(\"trans\")[2].alias(\"br_r\"),\n",
    "    col(\"trans\")[3].alias(\"br_x\"),\n",
    "    col(\"trans\")[4].alias(\"rate_a\"),\n",
    "    col(\"trans\")[7].alias(\"tap\")\n",
    ")\n",
    "\n",
    "trans_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Aggregate transformer features per snapshot\n",
    "trans_agg = trans_df.groupBy(\"filename\").agg(\n",
    "    avg(\"br_r\").alias(\"trans_br_r_mean\"),\n",
    "    avg(\"br_x\").alias(\"trans_br_x_mean\"),\n",
    "    spark_sum(\"rate_a\").alias(\"trans_rate_a_sum\"),\n",
    "    avg(\"tap\").alias(\"tap_mean\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, extract the objetive value (total cost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            filename|        total_cost|\n",
      "+--------------------+------------------+\n",
      "|gs://dataproc-tem...| 443934.8106702195|\n",
      "|gs://dataproc-tem...|465533.45792886155|\n",
      "|gs://dataproc-tem...| 462092.4328079719|\n",
      "|gs://dataproc-tem...| 453110.9782805654|\n",
      "|gs://dataproc-tem...|452267.02218503354|\n",
      "+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Extract the objective value directly from metadata\n",
    "obj_df = df.select(\n",
    "    \"filename\",\n",
    "    col(\"metadata.`objective`\").alias(\"total_cost\") \n",
    ")\n",
    "\n",
    "\n",
    "obj_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will merge aggregated data from different sources and ensures data consistency by checking for duplicate entries. Here are the main steps:\n",
    "  \n",
    "- Joining aggregated data from generator, load, transmission line, transformer and objective value based on \"filename\" into a single DataFrame.\n",
    "- Validating the aggregated results\n",
    "- Checking for duplicate filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows after aggregation: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------+--------------+------------------+------+------------------+-----------------+------------------+---------+------------------+--------------------+--------------------+------------------+----------+----------+---------------------+-------------------+-----------------+------------------+------------------+\n",
      "|filename                                                                                                                                   |num_generators|total_pg          |avg_vg|avg_cost_squared  |avg_cost_linear  |avg_cost_offset   |num_loads|total_pd          |br_r_mean           |br_x_mean           |rate_a_sum        |rate_b_min|rate_c_max|trans_br_r_mean      |trans_br_x_mean    |trans_rate_a_sum |tap_mean          |total_cost        |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------+--------------+------------------+------+------------------+-----------------+------------------+---------+------------------+--------------------+--------------------+------------------+----------+----------+---------------------+-------------------+-----------------+------------------+------------------+\n",
      "|gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15016.json|171           |154.14844499999998|1.0   |101.79871345029237|2637.030994152047|-4.104877192982458|281      |178.04577946859646|0.028101742751865683|0.028101742751865683|3.3398004439999984|0.00100208|999.99    |0.0035312410192708294|0.12213300296875002|846.2510999999997|1.0187825520833336|456028.843730449  |\n",
      "|gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15060.json|171           |154.14844499999998|1.0   |101.79871345029237|2637.030994152047|-4.104877192982458|281      |176.65926033122088|0.028101742751865683|0.028101742751865683|3.3398004439999984|0.00100208|999.99    |0.0035312410192708294|0.12213300296875002|846.2510999999997|1.0187825520833336|449745.3906636747 |\n",
      "|gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15017.json|171           |154.14844499999998|1.0   |101.79871345029237|2637.030994152047|-4.104877192982458|281      |176.0414097996017 |0.028101742751865683|0.028101742751865683|3.3398004439999984|0.00100208|999.99    |0.0035312410192708294|0.12213300296875002|846.2510999999997|1.0187825520833336|447069.17396169895|\n",
      "|gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15043.json|171           |154.14844499999998|1.0   |101.79871345029237|2637.030994152047|-4.104877192982458|281      |178.3610458590039 |0.028101742751865683|0.028101742751865683|3.3398004439999984|0.00100208|999.99    |0.0035312410192708294|0.12213300296875002|846.2510999999997|1.0187825520833336|457733.21321591106|\n",
      "|gs://dataproc-temp-us-central1-299400297029-n5lhuci2/gridopt-dataset-tmp/dataset_release_1/pglib_opf_case500_goc/group_1/example_15040.json|171           |154.14844499999998|1.0   |101.79871345029237|2637.030994152047|-4.104877192982458|281      |176.31096444945032|0.028101742751865683|0.028101742751865683|3.3398004439999984|0.00100208|999.99    |0.0035312410192708294|0.12213300296875002|846.2510999999997|1.0187825520833336|448213.1858805311 |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------+--------------+------------------+------+------------------+-----------------+------------------+---------+------------------+--------------------+--------------------+------------------+----------+----------+---------------------+-------------------+-----------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/24 19:49:46 WARN YarnAllocator: Container from a bad node: container_1742845605281_0001_01_000002 on host: cluster-2c22-m.us-central1-c.c.longy4bigdata25.internal. Exit status: 143. Diagnostics: [2025-03-24 19:49:46.474]Container killed on request. Exit code is 143\n",
      "[2025-03-24 19:49:46.477]Container exited with a non-zero exit code 143. \n",
      "[2025-03-24 19:49:46.482]Killed by external signal\n",
      ".\n",
      "25/03/24 19:49:46 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 2 for reason Container from a bad node: container_1742845605281_0001_01_000002 on host: cluster-2c22-m.us-central1-c.c.longy4bigdata25.internal. Exit status: 143. Diagnostics: [2025-03-24 19:49:46.474]Container killed on request. Exit code is 143\n",
      "[2025-03-24 19:49:46.477]Container exited with a non-zero exit code 143. \n",
      "[2025-03-24 19:49:46.482]Killed by external signal\n",
      ".\n",
      "25/03/24 19:49:46 ERROR YarnScheduler: Lost executor 2 on cluster-2c22-m.us-central1-c.c.longy4bigdata25.internal: Container from a bad node: container_1742845605281_0001_01_000002 on host: cluster-2c22-m.us-central1-c.c.longy4bigdata25.internal. Exit status: 143. Diagnostics: [2025-03-24 19:49:46.474]Container killed on request. Exit code is 143\n",
      "[2025-03-24 19:49:46.477]Container exited with a non-zero exit code 143. \n",
      "[2025-03-24 19:49:46.482]Killed by external signal\n",
      ".\n",
      "25/03/24 19:49:46 WARN TaskSetManager: Lost task 0.0 in stage 38.0 (TID 161) (cluster-2c22-m.us-central1-c.c.longy4bigdata25.internal executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container from a bad node: container_1742845605281_0001_01_000002 on host: cluster-2c22-m.us-central1-c.c.longy4bigdata25.internal. Exit status: 143. Diagnostics: [2025-03-24 19:49:46.474]Container killed on request. Exit code is 143\n",
      "[2025-03-24 19:49:46.477]Container exited with a non-zero exit code 143. \n",
      "[2025-03-24 19:49:46.482]Killed by external signal\n",
      ".\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All filenames are unique\n"
     ]
    }
   ],
   "source": [
    "# Use inner joins on 'filename' (the snapshot key) to combine all real values\n",
    "agg_df = gen_agg.join(load_agg, \"filename\", \"inner\") \\\n",
    "                .join(ac_line_agg, \"filename\", \"inner\") \\\n",
    "                .join(trans_agg, \"filename\", \"inner\") \\\n",
    "                .join(obj_df, \"filename\", \"inner\")\n",
    "\n",
    "# Validate the result\n",
    "print(\"Total number of rows after aggregation:\", agg_df.count())\n",
    "agg_df.show(5, truncate=False)  # Display the first 5 rows without truncation\n",
    "\n",
    "# Check for duplicate filenames\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "duplicate_check = agg_df.groupBy(\"filename\").agg(\n",
    "    F.count(\"*\").alias(\"count\")\n",
    ").filter(F.col(\"count\") > 1)\n",
    "\n",
    "if duplicate_check.count() == 0:\n",
    "    print(\"All filenames are unique\")\n",
    "else:\n",
    "    print(\"Duplicate filenames exist! Data consistency needs to be checked\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Address missing data\n",
    "Author: Ewan Long\n",
    "\n",
    "Date: 03/24/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, I will do the data quality checks, and manages any potential missing data, and enforces consistency for a prepared aggregated dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, Calculates the count and proportion of missing values for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/24 19:59:16 WARN YarnAllocator: Container from a bad node: container_1742845605281_0001_01_000001 on host: cluster-2c22-m.us-central1-c.c.longy4bigdata25.internal. Exit status: 143. Diagnostics: [2025-03-24 19:59:16.492]Container killed on request. Exit code is 143\n",
      "[2025-03-24 19:59:16.492]Container exited with a non-zero exit code 143. \n",
      "[2025-03-24 19:59:16.492]Killed by external signal\n",
      ".\n",
      "25/03/24 19:59:16 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 1 for reason Container from a bad node: container_1742845605281_0001_01_000001 on host: cluster-2c22-m.us-central1-c.c.longy4bigdata25.internal. Exit status: 143. Diagnostics: [2025-03-24 19:59:16.492]Container killed on request. Exit code is 143\n",
      "[2025-03-24 19:59:16.492]Container exited with a non-zero exit code 143. \n",
      "[2025-03-24 19:59:16.492]Killed by external signal\n",
      ".\n",
      "25/03/24 19:59:16 ERROR YarnScheduler: Lost executor 1 on cluster-2c22-m.us-central1-c.c.longy4bigdata25.internal: Container from a bad node: container_1742845605281_0001_01_000001 on host: cluster-2c22-m.us-central1-c.c.longy4bigdata25.internal. Exit status: 143. Diagnostics: [2025-03-24 19:59:16.492]Container killed on request. Exit code is 143\n",
      "[2025-03-24 19:59:16.492]Container exited with a non-zero exit code 143. \n",
      "[2025-03-24 19:59:16.492]Killed by external signal\n",
      ".\n",
      "25/03/24 19:59:16 WARN TaskSetManager: Lost task 1.0 in stage 56.0 (TID 199) (cluster-2c22-m.us-central1-c.c.longy4bigdata25.internal executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container from a bad node: container_1742845605281_0001_01_000001 on host: cluster-2c22-m.us-central1-c.c.longy4bigdata25.internal. Exit status: 143. Diagnostics: [2025-03-24 19:59:16.492]Container killed on request. Exit code is 143\n",
      "[2025-03-24 19:59:16.492]Container exited with a non-zero exit code 143. \n",
      "[2025-03-24 19:59:16.492]Killed by external signal\n",
      ".\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count missing values per column\n",
    "missing_count_df = agg_df.select([\n",
    "    F.count(F.when(F.isnull(c), c)).alias(c) for c in agg_df.columns\n",
    "])\n",
    "\n",
    "# Total rows in DataFrame\n",
    "total_rows = agg_df.count()\n",
    "total_row_df = spark.createDataFrame([(total_rows,)], [\"total_rows\"])\n",
    "\n",
    "# Combine counts and total row number via cross join\n",
    "missing_stats = missing_count_df.crossJoin(total_row_df)\n",
    "\n",
    "# Compute missing ratios\n",
    "missing_stats = missing_stats.select(\n",
    "    # Original missing counts\n",
    "    *[F.col(c) for c in agg_df.columns],\n",
    "    # Missing ratio per column\n",
    "    *[(F.col(c) / F.col(\"total_rows\")).alias(f\"{c}_missing_ratio\") for c in agg_df.columns]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the overview of missing values and their ratios for each column in the aggregated DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 100\n"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Display missing value statistics clearly\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal rows: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_rows\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmissing_stats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvertical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m  \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# using vertical=True improves readability for large number of columns\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py:947\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mshow\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, truncate: Union[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, vertical: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    888\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m \n\u001b[1;32m    890\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;124;03m    name | Bob\u001b[39;00m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py:978\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    971\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    972\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    975\u001b[0m         },\n\u001b[1;32m    976\u001b[0m     )\n\u001b[0;32m--> 978\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mint_truncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.11/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.11/site-packages/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.11/site-packages/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.11/site-packages/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.11/site-packages/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "# Display missing value statistics clearly\n",
    "print(f\"Total rows: {total_rows}\")\n",
    "missing_stats.show(vertical=True, truncate=False)  \n",
    "# using vertical=True improves readability for large number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
